# ‚úÖ SCHEMA VERIFICATION - SUMMARY

## üéØ K·∫æT QU·∫¢ KI·ªÇM TRA

ƒê√£ ki·ªÉm tra k·ªπ 4 ngu·ªìn d·ªØ li·ªáu th·∫≠t v√† t·∫°o schemas ch√≠nh x√°c.

---

## üìä SO S√ÅNH SCHEMAS

| Data Source          | Original Schema   | Corrected Schema            | Status             |
| -------------------- | ----------------- | --------------------------- | ------------------ |
| **Weather (Kaggle)** | `data_schemas.py` | `data_schemas_corrected.py` | ‚ö†Ô∏è UPDATED         |
| **311 Requests**     | `data_schemas.py` | `data_schemas_corrected.py` | ‚úÖ ENHANCED        |
| **Taxi Trips**       | `data_schemas.py` | `data_schemas_corrected.py` | ‚ö†Ô∏è SPLIT 2016/2017 |
| **Collisions**       | `data_schemas.py` | `data_schemas_corrected.py` | ‚úÖ ENHANCED        |

---

## üî¥ THAY ƒê·ªîI QUAN TR·ªåNG

### 1. Weather Data

**Problem:** Kaggle data l√† WIDE FORMAT (columns = cities)

```
datetime          | Vancouver | Portland | ...
2016-01-01 00:00  | 282.5     | 289.3    | ...
```

**Solution:** Schema cho LONG FORMAT (sau khi melt)

```
datetime          | city      | temperature
2016-01-01 00:00  | Vancouver | 282.5
2016-01-01 00:00  | Portland  | 289.3
```

**File:** `data_schemas_corrected.py` - `weather_schema_long`

---

### 2. Taxi Trips - 2 VERSIONS

#### 2016 Data (b·∫°n d√πng):

```python
‚úÖ C√ì: pickup_longitude, pickup_latitude
‚úÖ C√ì: dropoff_longitude, dropoff_latitude
‚úÖ C√ì: improvement_surcharge
‚ùå KH√îNG C√ì: PULocationID, DOLocationID
```

#### 2017+ Data:

```python
‚ùå KH√îNG C√ì: coordinates (lat/lon)
‚úÖ C√ì: PULocationID, DOLocationID
‚úÖ C√ì: improvement_surcharge, congestion_surcharge
```

**Files:**

- `taxi_trip_schema_2016` - For 2016 data
- `taxi_trip_schema_2017` - For 2017+ data

---

### 3. 311 Requests - ENHANCED

**Added:**

- `due_date`
- `resolution_description`
- `community_board`

---

### 4. Collisions - ENHANCED

**Added:**

- `collision_id` (unique identifier)
- `off_street_name`

---

## üìù C√ÅCH S·ª¨ D·ª§NG

### Option 1: D√πng Corrected Schemas (RECOMMENDED)

```python
# Trong main_etl.py, thay import:
# OLD:
from schemas.data_schemas import *

# NEW:
from schemas.data_schemas_corrected import *
```

### Option 2: Gi·ªØ c·∫£ 2 files

```python
# Use corrected cho production
from schemas.data_schemas_corrected import (
    weather_schema_long,
    taxi_trip_schema_2016,
    collision_schema
)

# Use original cho testing
from schemas.data_schemas import weather_schema
```

---

## üîß UPDATES REQUIRED IN CODE

### 1. Update Readers (`readers/data_readers.py`)

```python
# For Weather Data - need to handle wide ‚Üí long melt
def read_weather_data_kaggle(path):
    # Read temperature.csv
    df_temp = spark.read.csv(f"{path}/temperature.csv", header=True)

    # Melt wide format ‚Üí long format
    city_cols = [c for c in df_temp.columns if c != 'datetime']
    expr_str = f"stack({len(city_cols)}, " + \
               ", ".join([f"'{c}', `{c}`" for c in city_cols]) + \
               ") as (city, temperature)"

    df_long = df_temp.selectExpr("datetime", expr_str)
    return df_long

# For Taxi Data - auto-detect year
def read_taxi_data(path, year=2016):
    from schemas.data_schemas_corrected import get_schema

    schema = get_schema("taxi", year=year)
    df = spark.read.csv(path, schema=schema, header=True)
    return df
```

### 2. Update Main ETL (`main_etl.py`)

```python
# Import corrected schemas
from schemas.data_schemas_corrected import (
    weather_schema_long,
    taxi_trip_schema_2016,
    service_311_schema,
    collision_schema
)

# Or use helper function
from schemas.data_schemas_corrected import get_schema

weather_schema = get_schema("weather")
taxi_schema = get_schema("taxi", year=2016)
collision_schema = get_schema("collision")
```

---

## ‚ö° QUICK FIX CHECKLIST

- [ ] Update imports to use `data_schemas_corrected.py`
- [ ] Add melt logic for weather data in reader
- [ ] Use year-specific taxi schema (2016 vs 2017)
- [ ] Update fake data generators to match new schemas
- [ ] Test with corrected schemas

---

## üìö FILES REFERENCE

1. **`DATA_SOURCES_VERIFIED.md`** - Chi ti·∫øt verification process
2. **`schemas/data_schemas.py`** - Original schemas (keep for reference)
3. **`schemas/data_schemas_corrected.py`** - ‚úÖ CORRECTED schemas (use this!)

---

## ‚úÖ RECOMMENDATION

**FOR 2016 DATA (your use case):**

1. Use `data_schemas_corrected.py`
2. Import schemas:

   ```python
   from schemas.data_schemas_corrected import (
       weather_schema_long,
       taxi_trip_schema_2016,  # ‚Üê For 2016 data
       service_311_schema,
       collision_schema
   )
   ```

3. Add melt logic in weather reader
4. Done! Ready to process real data

---

B·∫°n c√≥ mu·ªën t√¥i update lu√¥n code trong `main_etl.py` v√† `readers/data_readers.py` kh√¥ng? üîß
