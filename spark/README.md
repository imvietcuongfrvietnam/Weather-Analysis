# âš¡ Spark Processing Engine - Weather Analysis Project

Module nÃ y lÃ  trÃ¡i tim cá»§a há»‡ thá»‘ng Big Data, chá»‹u trÃ¡ch nhiá»‡m xá»­ lÃ½ dá»¯ liá»‡u theo kiáº¿n trÃºc **Lambda Architecture**. NÃ³ bao gá»“m cÃ¡c tÃ¡c vá»¥ xá»­ lÃ½ luá»“ng (Streaming ETL) vÃ  xá»­ lÃ½ lÃ´ (Batch Machine Learning).

## ğŸ—ï¸ Kiáº¿n trÃºc & Luá»“ng dá»¯ liá»‡u

Há»‡ thá»‘ng Spark Ä‘Æ°á»£c chia thÃ nh 2 luá»“ng xá»­ lÃ½ chÃ­nh:

1.  **Speed Layer (Streaming Job):**
    * Äá»c dá»¯ liá»‡u Real-time tá»« **Kafka**.
    * LÃ m sáº¡ch (Cleaning) vÃ  chuáº©n hÃ³a (Normalization).
    * Ghi dá»¯ liá»‡u nÃ³ng vÃ o **Redis** (cho Dashboard Realtime).
    * Ghi dá»¯ liá»‡u láº¡nh vÃ o **MinIO** (dáº¡ng Parquet) Ä‘á»ƒ lÆ°u trá»¯ lá»‹ch sá»­.

2.  **Batch Layer (ML Job):**
    * Äá»c dá»¯ liá»‡u lá»‹ch sá»­ tá»« **MinIO**.
    * Feature Engineering (táº¡o lag features, rolling windows).
    * Huáº¥n luyá»‡n mÃ´ hÃ¬nh (Regression/Classification) sá»­ dá»¥ng **Spark MLlib**.
    * LÆ°u Model vÃ o MinIO vÃ  ghi káº¿t quáº£ dá»± bÃ¡o vÃ o **PostgreSQL**.

---

## ğŸ“‚ Cáº¥u trÃºc thÆ° má»¥c

spark/
â”œâ”€â”€ config/                 # Cáº¥u hÃ¬nh há»‡ thá»‘ng (MinIO, Kafka, Redis, Postgres)
â”‚   â””â”€â”€ config.py
â”œâ”€â”€ job/                    # CÃ¡c Spark Job chÃ­nh (Entry points)
â”‚   â”œâ”€â”€ main_etl.py         # Job Streaming ETL (Kafka -> MinIO/Redis)
â”‚   â””â”€â”€ spark_ml_job.py     # Job Batch ML (Training & Forecasting)
â”œâ”€â”€ readers/                # Modules Ä‘á»c dá»¯ liá»‡u
â”‚   â””â”€â”€ real_data_reader.py # Äá»c tá»« Kafka/MinIO
â”œâ”€â”€ writers/                # Modules ghi dá»¯ liá»‡u
â”‚   â”œâ”€â”€ minio_writer.py     # Ghi Parquet xuá»‘ng Data Lake
â”‚   â”œâ”€â”€ redis_data_writer.py# Ghi xuá»‘ng Redis
â”‚   â””â”€â”€ postgres_writer.py  # Ghi káº¿t quáº£ dá»± bÃ¡o xuá»‘ng DB
â”œâ”€â”€ transformations/        # Logic biáº¿n Ä‘á»•i dá»¯ liá»‡u
â”‚   â”œâ”€â”€ cleaning.py         # LÃ m sáº¡ch, xá»­ lÃ½ null
â”‚   â””â”€â”€ normalization.py    # Chuáº©n hÃ³a dá»¯ liá»‡u
â”œâ”€â”€ schemas/                # Äá»‹nh nghÄ©a Schema (StructType)
â”‚   â””â”€â”€ data_schemas.py
â”œâ”€â”€ feature_engineering.py  # Táº¡o Ä‘áº·c trÆ°ng cho ML
â”œâ”€â”€ models.py               # Äá»‹nh nghÄ©a cÃ¡c thuáº­t toÃ¡n ML
â”œâ”€â”€ data_loader.py          # Helper load dá»¯ liá»‡u cho ML
â”œâ”€â”€ connection_utils.py     # Tiá»‡n Ã­ch káº¿t ná»‘i
â””â”€â”€ requirements.txt        # CÃ¡c thÆ° viá»‡n Python cáº§n thiáº¿t

## ğŸš€ HÆ°á»›ng dáº«n cháº¡y (Deployment)

MÃ£ nguá»“n nÃ y Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ cháº¡y trÃªn mÃ´i trÆ°á»ng **Kubernetes** thÃ´ng qua **Apache Airflow**, nhÆ°ng cÅ©ng cÃ³ thá»ƒ cháº¡y Local Ä‘á»ƒ kiá»ƒm thá»­.

### 1. YÃªu cáº§u mÃ´i trÆ°á»ng (Prerequisites)
* Python 3.9+
* Apache Spark 3.x
* Java 11 (cho Spark)
* CÃ¡c dá»‹ch vá»¥ phá»¥ trá»£ Ä‘ang cháº¡y: Kafka, MinIO, Redis, PostgreSQL.

### 2. CÃ i Ä‘áº·t thÆ° viá»‡n
pip install -r requirements.txt

### 3. Cháº¡y Streaming Job (ETL)
Job nÃ y sáº½ cháº¡y vÃ´ háº¡n, láº¯ng nghe Kafka vÃ  Ä‘áº©y dá»¯ liá»‡u Ä‘i.

# Cháº¡y local
python job/main_etl.py

# Cháº¡y vá»›i spark-submit (Production)
spark-submit \
  --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0,org.apache.hadoop:hadoop-aws:3.3.4 \
  job/main_etl.py

### 4. Cháº¡y Batch Job (Machine Learning)
Job nÃ y sáº½ train model dá»±a trÃªn dá»¯ liá»‡u hiá»‡n cÃ³ trong MinIO.

# Cháº¡y local
python job/spark_ml_job.py

# Cháº¡y vá»›i spark-submit
spark-submit \
  --packages org.apache.hadoop:hadoop-aws:3.3.4,org.postgresql:postgresql:42.6.0 \
  job/spark_ml_job.py

---

## âš™ï¸ Cáº¥u hÃ¬nh (Configuration)

ToÃ n bá»™ cáº¥u hÃ¬nh Ä‘Æ°á»£c quáº£n lÃ½ táº­p trung táº¡i `config/config.py`. Báº¡n cÃ³ thá»ƒ thay Ä‘á»•i cÃ¡c thÃ´ng sá»‘ sau báº±ng biáº¿n mÃ´i trÆ°á»ng hoáº·c sá»­a trá»±c tiáº¿p file:

| Tham sá»‘ | MÃ´ táº£ | Máº·c Ä‘á»‹nh |
| :--- | :--- | :--- |
| `KAFKA_BOOTSTRAP_SERVERS` | Äá»‹a chá»‰ Kafka Broker | `my-cluster-kafka-bootstrap:9092` |
| `MINIO_ENDPOINT` | Endpoint cá»§a MinIO | `weather-minio:9000` |
| `REDIS_HOST` | Äá»‹a chá»‰ Redis | `weather-redis` |
| `POSTGRES_HOST` | Äá»‹a chá»‰ PostgreSQL | `weather-postgresql` |
| `SPARK_MASTER` | Spark Master URL | `local[*]` (hoáº·c `spark://...`) |

---

## ğŸ› ï¸ CÃ¡c module chÃ­nh

### `transformations/`
Chá»©a cÃ¡c hÃ m Pure Functions Ä‘á»ƒ biáº¿n Ä‘á»•i DataFrame:
- **`clean_data(df)`**: Xá»­ lÃ½ giÃ¡ trá»‹ NULL, Ã©p kiá»ƒu dá»¯ liá»‡u.
- **`normalize_data(df)`**: Chuáº©n hÃ³a tÃªn thÃ nh phá»‘, Ä‘Æ¡n vá»‹ Ä‘o lÆ°á»ng.

### `feature_engineering.py`
Táº¡o cÃ¡c Ä‘áº·c trÆ°ng nÃ¢ng cao cho Machine Learning:
- **Lag Features**: Nhiá»‡t Ä‘á»™ cá»§a 1h, 3h trÆ°á»›c.
- **Rolling Window**: Trung bÃ¬nh trÆ°á»£t cá»§a 3h gáº§n nháº¥t.
- **Time Components**: TrÃ­ch xuáº¥t giá», ngÃ y, thÃ¡ng, mÃ¹a tá»« timestamp.

### `models.py`
Quáº£n lÃ½ vÃ²ng Ä‘á»i cá»§a Model:
- **Train**: Há»— trá»£ GBTRegressor, RandomForestRegressor.
- **Save/Load**: LÆ°u model Ä‘Ã£ train xuá»‘ng MinIO Ä‘á»ƒ tÃ¡i sá»­ dá»¥ng.
- **Evaluate**: TÃ­nh toÃ¡n RMSE, MAE, R2.

---

## ğŸ“ Troubleshooting (Gá»¡ lá»—i thÆ°á»ng gáº·p)

1.  **Lá»—i `S3AFileSystem: The specified bucket does not exist`**:
    * Äáº£m báº£o bucket `weather-data` Ä‘Ã£ Ä‘Æ°á»£c táº¡o trÃªn MinIO.

2.  **Lá»—i `ConnectionRefused` tá»›i Kafka/Redis**:
    * Kiá»ƒm tra láº¡i `config.py`.
    * Náº¿u cháº¡y trÃªn K8s: DÃ¹ng Service Name (vÃ­ dá»¥ `weather-redis`).
    * Náº¿u cháº¡y Local: DÃ¹ng `localhost` vÃ  Port-forwarding.

3.  **Lá»—i `AnalysisException: Path does not exist` khi cháº¡y ML Job**:
    * Do Streaming Job chÆ°a cháº¡y hoáº·c chÆ°a ghi Ä‘á»§ dá»¯ liá»‡u xuá»‘ng MinIO. HÃ£y cháº¡y Streaming Job trÆ°á»›c Ã­t nháº¥t 5 phÃºt Ä‘á»ƒ cÃ³ dá»¯ liá»‡u.

