import os

# ===========================
# WEATHER POSTGRESQL CONFIGURATION
# ===========================

# S·ª¨A T·∫†I ƒê√ÇY: D√πng FQDN ƒë·ªÉ g·ªçi t·ª´ namespace 'airflow' sang namespace 'default'
POSTGRES_HOST = os.getenv("POSTGRES_HOST", "weather-postgresql.default.svc.cluster.local")
POSTGRES_PORT = os.getenv("POSTGRES_PORT", "5432")
POSTGRES_DATABASE = os.getenv("POSTGRES_DB", "weather_db")

# Th√¥ng tin user/pass (ƒê·∫£m b·∫£o kh·ªõp v·ªõi Database b·∫°n ƒë√£ kh·ªüi t·∫°o trong namespace default)
POSTGRES_USER = os.getenv("POSTGRES_USER", "weather_user")
POSTGRES_PASSWORD = os.getenv("POSTGRES_PASSWORD", "weather_pass")

POSTGRES_DRIVER = "org.postgresql.Driver"
FORECAST_TABLE = os.getenv("POSTGRES_TABLE", "weather_predictions")

# JDBC URL s·∫Ω t·ª± ƒë·ªông c·∫≠p nh·∫≠t theo HOST m·ªõi
POSTGRES_JDBC_URL = f"jdbc:postgresql://{POSTGRES_HOST}:{POSTGRES_PORT}/{POSTGRES_DATABASE}"

SPARK_POSTGRES_CONFIG = {
    "url": POSTGRES_JDBC_URL,
    "driver": POSTGRES_DRIVER,
    "user": POSTGRES_USER,
    "password": POSTGRES_PASSWORD,
    "dbtable": FORECAST_TABLE,
    # Th√™m tham s·ªë n√†y ƒë·ªÉ Spark ML ghi d·ªØ li·ªáu m∆∞·ª£t h∆°n
    "batchsize": "1000",
    "reWriteBatchedInserts": "true"
}

def print_config():
    """In ra c·∫•u h√¨nh hi·ªán t·∫°i ƒë·ªÉ debug tr√™n Airflow Logs"""
    print("\n" + "="*80)
    print("üêò WEATHER POSTGRESQL CONFIGURATION (CROSS-NAMESPACE)")
    print("="*80)
    print(f"Host FQDN:    {POSTGRES_HOST}")
    print(f"Database:     {POSTGRES_DATABASE}")
    print(f"JDBC URL:     {POSTGRES_JDBC_URL}")
    print("="*80 + "\n")

if __name__ == "__main__":
    print_config()