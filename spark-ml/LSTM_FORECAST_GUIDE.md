# HÆ°á»›ng Dáº«n: Dá»± ÄoÃ¡n Thá»i Tiáº¿t 7 NgÃ y Tá»›i báº±ng LSTM

## ğŸ“‹ Tá»•ng Quan

Pipeline nÃ y Ä‘á»c dá»¯ liá»‡u thá»i tiáº¿t tá»« MinIO, sá»­ dá»¥ng mÃ´ hÃ¬nh LSTM (Long Short-Term Memory) Ä‘á»ƒ dá»± Ä‘oÃ¡n cÃ¡c giÃ¡ trá»‹ thá»i tiáº¿t trong 7 ngÃ y tá»›i, vÃ  ghi káº¿t quáº£ vÃ o PostgreSQL.

## ğŸ—ï¸ Kiáº¿n TrÃºc Pipeline

```
MinIO (Parquet) â†’ Spark â†’ LSTM Model â†’ PostgreSQL â†’ Grafana
```

1. **MinIO**: LÆ°u trá»¯ dá»¯ liá»‡u thá»i tiáº¿t Ä‘Ã£ Ä‘Æ°á»£c xá»­ lÃ½ (tá»« ETL pipeline)
2. **Spark**: Äá»c vÃ  xá»­ lÃ½ dá»¯ liá»‡u tá»« MinIO
3. **LSTM Model**: MÃ´ hÃ¬nh deep learning Ä‘á»ƒ dá»± Ä‘oÃ¡n time series
4. **PostgreSQL**: LÆ°u trá»¯ káº¿t quáº£ dá»± Ä‘oÃ¡n
5. **Grafana**: Visualize dá»¯ liá»‡u (tÃ¹y chá»n)

## ğŸ“¦ YÃªu Cáº§u Há»‡ Thá»‘ng

### 1. Pháº§n Má»m Cáº§n CÃ i Äáº·t

```bash
# Python dependencies
pip install -r ../spark_etl_weather_disaster/requirements.txt

# Hoáº·c cÃ i Ä‘áº·t tá»«ng package:
pip install pyspark>=3.3.0
pip install pandas>=1.5.0
pip install numpy>=1.23.0
pip install tensorflow>=2.10.0
pip install scikit-learn>=1.0.0
pip install psycopg2-binary>=2.9.0
pip install minio
pip install pyarrow>=10.0.0
```

### 2. Spark Packages

Khi cháº¡y vá»›i `spark-submit`, cáº§n thÃªm cÃ¡c packages:

```bash
spark-submit \
  --packages org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.262,org.postgresql:postgresql:42.5.0 \
  spark_lstm_forecast.py
```

### 3. Services Cáº§n Cháº¡y

- **MinIO**: Server lÆ°u trá»¯ dá»¯ liá»‡u (localhost:9000)
- **PostgreSQL**: Database server (localhost:5432)

## ğŸš€ HÆ°á»›ng Dáº«n CÃ i Äáº·t vÃ  Cháº¡y

### BÆ°á»›c 1: CÃ i Äáº·t PostgreSQL

#### Option A: Docker (Khuyáº¿n nghá»‹)

```bash
# Cháº¡y PostgreSQL container
docker run --name postgres-weather \
  -e POSTGRES_DB=weather_db \
  -e POSTGRES_USER=weather_user \
  -e POSTGRES_PASSWORD=weather_pass \
  -p 5432:5432 \
  -d postgres:15

# Kiá»ƒm tra container Ä‘ang cháº¡y
docker ps | grep postgres-weather
```

#### Option B: CÃ i Äáº·t Local

1. Táº£i vÃ  cÃ i Ä‘áº·t PostgreSQL tá»« https://www.postgresql.org/download/
2. Táº¡o database vÃ  user:

```sql
CREATE DATABASE weather_db;
CREATE USER weather_user WITH PASSWORD 'weather_pass';
GRANT ALL PRIVILEGES ON DATABASE weather_db TO weather_user;
```

### BÆ°á»›c 2: Táº¡o Báº£ng PostgreSQL

Káº¿t ná»‘i vÃ o PostgreSQL vÃ  cháº¡y script sau:

```sql
-- Káº¿t ná»‘i vÃ o database
\c weather_db

-- Táº¡o báº£ng forecasts
CREATE TABLE IF NOT EXISTS weather_forecasts (
    id SERIAL PRIMARY KEY,
    city VARCHAR(100) NOT NULL,
    forecast_date DATE NOT NULL,
    forecast_datetime TIMESTAMP NOT NULL,
    temperature_celsius DOUBLE PRECISION,
    humidity_pct DOUBLE PRECISION,
    pressure_hpa DOUBLE PRECISION,
    wind_speed_kmh DOUBLE PRECISION,
    wind_direction_deg DOUBLE PRECISION,
    model_version VARCHAR(50),
    prediction_timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    confidence_score DOUBLE PRECISION,
    UNIQUE(city, forecast_date, forecast_datetime)
);

-- Táº¡o indexes Ä‘á»ƒ query nhanh hÆ¡n
CREATE INDEX IF NOT EXISTS idx_forecast_city_date ON weather_forecasts(city, forecast_date);
CREATE INDEX IF NOT EXISTS idx_forecast_datetime ON weather_forecasts(forecast_datetime);

-- Cáº¥p quyá»n cho user
GRANT ALL PRIVILEGES ON TABLE weather_forecasts TO weather_user;
GRANT USAGE, SELECT ON SEQUENCE weather_forecasts_id_seq TO weather_user;
```

Hoáº·c sá»­ dá»¥ng Python script:

```python
import psycopg2
import sys
sys.path.append('../spark_etl_weather_disaster')
import postgres_config

conn = psycopg2.connect(
    host=postgres_config.POSTGRES_HOST,
    port=postgres_config.POSTGRES_PORT,
    database=postgres_config.POSTGRES_DATABASE,
    user=postgres_config.POSTGRES_USER,
    password=postgres_config.POSTGRES_PASSWORD
)

cursor = conn.cursor()
cursor.execute(postgres_config.FORECAST_TABLE_SCHEMA)
conn.commit()
cursor.close()
conn.close()
print("âœ… Báº£ng Ä‘Ã£ Ä‘Æ°á»£c táº¡o!")
```

### BÆ°á»›c 3: Kiá»ƒm Tra MinIO

Äáº£m báº£o MinIO Ä‘ang cháº¡y vÃ  cÃ³ dá»¯ liá»‡u:

```bash
# Kiá»ƒm tra MinIO Ä‘ang cháº¡y
curl http://localhost:9000/minio/health/live

# Hoáº·c truy cáº­p web UI: http://localhost:9001
```

Äáº£m báº£o cÃ³ dá»¯ liá»‡u trong bucket `weather-data/enriched/weather/` (Parquet format).

### BÆ°á»›c 4: Cáº¥u HÃ¬nh

Kiá»ƒm tra vÃ  cáº­p nháº­t cÃ¡c file config náº¿u cáº§n:

1. **MinIO Config** (`../spark_etl_weather_disaster/minio_config.py`):
   ```python
   MINIO_ENDPOINT = "localhost:9000"
   MINIO_ACCESS_KEY = "minioadmin"
   MINIO_SECRET_KEY = "minioadmin"
   MINIO_BUCKET = "weather-data"
   ```

2. **PostgreSQL Config** (`../spark_etl_weather_disaster/postgres_config.py`):
   ```python
   POSTGRES_HOST = "localhost"
   POSTGRES_PORT = 5432
   POSTGRES_DATABASE = "weather_db"
   POSTGRES_USER = "weather_user"
   POSTGRES_PASSWORD = "weather_pass"
   ```

### BÆ°á»›c 5: Cháº¡y Pipeline

#### Option A: Cháº¡y trá»±c tiáº¿p vá»›i Python

```bash
cd spark-ml
python spark_lstm_forecast.py
```

#### Option B: Cháº¡y vá»›i spark-submit

```bash
cd spark-ml
spark-submit \
  --packages org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.262,org.postgresql:postgresql:42.5.0 \
  --driver-memory 4g \
  --executor-memory 4g \
  spark_lstm_forecast.py
```

## ğŸ“Š Cáº¥u TrÃºc MÃ´ HÃ¬nh LSTM

MÃ´ hÃ¬nh LSTM Ä‘Æ°á»£c xÃ¢y dá»±ng vá»›i kiáº¿n trÃºc sau:

```
Input Layer: (lookback_timesteps, n_features)
    â†“
LSTM Layer 1: 50 units, return_sequences=True
    â†“
Dropout: 0.2
    â†“
LSTM Layer 2: 50 units, return_sequences=True
    â†“
Dropout: 0.2
    â†“
LSTM Layer 3: 50 units
    â†“
Dropout: 0.2
    â†“
Dense Layer: n_features (output)
```

### Tham Sá»‘ MÃ´ HÃ¬nh

- **Lookback Window**: 30 ngÃ y (720 giá» náº¿u dá»¯ liá»‡u theo giá»)
- **Forecast Horizon**: 7 ngÃ y (168 giá»)
- **Features**: temperature, humidity, pressure, wind_speed, wind_direction
- **Batch Size**: 32
- **Epochs**: 50
- **Optimizer**: Adam (learning_rate=0.001)
- **Loss Function**: MSE (Mean Squared Error)

## ğŸ”§ TÃ¹y Chá»‰nh

### Thay Äá»•i Sá»‘ NgÃ y Dá»± ÄoÃ¡n

Trong `spark_lstm_forecast.py`:

```python
FORECAST_DAYS = 14  # Thay Ä‘á»•i tá»« 7 sang 14 ngÃ y
```

### Thay Äá»•i Lookback Window

```python
LOOKBACK_DAYS = 60  # TÄƒng tá»« 30 lÃªn 60 ngÃ y
```

### Thay Äá»•i Features

```python
FEATURE_COLUMNS = ['temperature', 'humidity', 'pressure']  # Bá» wind_speed vÃ  wind_direction
```

### Thay Äá»•i Hyperparameters

```python
BATCH_SIZE = 64  # TÄƒng batch size
EPOCHS = 100     # TÄƒng sá»‘ epochs
```

## ğŸ“ˆ Kiá»ƒm Tra Káº¿t Quáº£

### Query PostgreSQL

```sql
-- Xem táº¥t cáº£ dá»± Ä‘oÃ¡n
SELECT * FROM weather_forecasts ORDER BY forecast_datetime DESC LIMIT 100;

-- Xem dá»± Ä‘oÃ¡n cho má»™t thÃ nh phá»‘ cá»¥ thá»ƒ
SELECT city, forecast_datetime, temperature_celsius, humidity_pct 
FROM weather_forecasts 
WHERE city = 'New York' 
ORDER BY forecast_datetime;

-- Xem dá»± Ä‘oÃ¡n cho ngÃ y cá»¥ thá»ƒ
SELECT city, forecast_datetime, temperature_celsius 
FROM weather_forecasts 
WHERE forecast_date = '2024-01-15'
ORDER BY city, forecast_datetime;

-- Thá»‘ng kÃª theo thÃ nh phá»‘
SELECT 
    city, 
    COUNT(*) as forecast_count,
    AVG(temperature_celsius) as avg_temp,
    MIN(temperature_celsius) as min_temp,
    MAX(temperature_celsius) as max_temp
FROM weather_forecasts
GROUP BY city;
```

### Visualize vá»›i Python

```python
import psycopg2
import pandas as pd
import matplotlib.pyplot as plt
import sys
sys.path.append('../spark_etl_weather_disaster')
import postgres_config

# Káº¿t ná»‘i PostgreSQL
conn = psycopg2.connect(
    host=postgres_config.POSTGRES_HOST,
    port=postgres_config.POSTGRES_PORT,
    database=postgres_config.POSTGRES_DATABASE,
    user=postgres_config.POSTGRES_USER,
    password=postgres_config.POSTGRES_PASSWORD
)

# Äá»c dá»¯ liá»‡u
query = """
SELECT forecast_datetime, temperature_celsius, humidity_pct 
FROM weather_forecasts 
WHERE city = 'New York'
ORDER BY forecast_datetime
"""

df = pd.read_sql(query, conn)
conn.close()

# Váº½ biá»ƒu Ä‘á»“
fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))

ax1.plot(df['forecast_datetime'], df['temperature_celsius'])
ax1.set_title('Temperature Forecast')
ax1.set_xlabel('Date')
ax1.set_ylabel('Temperature (Â°C)')
ax1.grid(True)

ax2.plot(df['forecast_datetime'], df['humidity_pct'])
ax2.set_title('Humidity Forecast')
ax2.set_xlabel('Date')
ax2.set_ylabel('Humidity (%)')
ax2.grid(True)

plt.tight_layout()
plt.show()
```

## ğŸ› Xá»­ LÃ½ Lá»—i ThÆ°á»ng Gáº·p

### 1. Lá»—i Káº¿t Ná»‘i MinIO

```
âŒ Lá»—i Ä‘á»c dá»¯ liá»‡u tá»« MinIO: ...
```

**Giáº£i phÃ¡p:**
- Kiá»ƒm tra MinIO server Ä‘ang cháº¡y: `docker ps | grep minio`
- Kiá»ƒm tra endpoint trong `minio_config.py`
- Kiá»ƒm tra credentials (access key, secret key)
- Kiá»ƒm tra bucket vÃ  folder tá»“n táº¡i

### 2. Lá»—i Káº¿t Ná»‘i PostgreSQL

```
âŒ Lá»—i ghi vÃ o PostgreSQL: ...
```

**Giáº£i phÃ¡p:**
- Kiá»ƒm tra PostgreSQL Ä‘ang cháº¡y: `docker ps | grep postgres`
- Kiá»ƒm tra credentials trong `postgres_config.py`
- Kiá»ƒm tra database vÃ  table Ä‘Ã£ Ä‘Æ°á»£c táº¡o
- Kiá»ƒm tra PostgreSQL driver trong Spark classpath

### 3. Lá»—i KhÃ´ng Äá»§ Dá»¯ Liá»‡u

```
âŒ KhÃ´ng Ä‘á»§ dá»¯ liá»‡u Ä‘á»ƒ táº¡o sequences
```

**Giáº£i phÃ¡p:**
- Giáº£m `LOOKBACK_DAYS` trong config
- Äáº£m báº£o cÃ³ Ä‘á»§ dá»¯ liá»‡u trong MinIO (Ã­t nháº¥t vÃ i thÃ¡ng)
- Kiá»ƒm tra dá»¯ liá»‡u cÃ³ bá»‹ thiáº¿u khÃ´ng

### 4. Lá»—i Memory

```
OutOfMemoryError: Java heap space
```

**Giáº£i phÃ¡p:**
- TÄƒng driver memory: `--driver-memory 8g`
- Giáº£m sá»‘ thÃ nh phá»‘ xá»­ lÃ½ cÃ¹ng lÃºc
- Xá»­ lÃ½ tá»«ng thÃ nh phá»‘ má»™t thay vÃ¬ batch

### 5. Lá»—i TensorFlow

```
âš ï¸ TensorFlow khÃ´ng Ä‘Æ°á»£c cÃ i Ä‘áº·t
```

**Giáº£i phÃ¡p:**
```bash
pip install tensorflow>=2.10.0
```

## ğŸ”„ TÃ­ch Há»£p vá»›i Airflow (TÃ¹y chá»n)

Äá»ƒ tá»± Ä‘á»™ng hÃ³a pipeline, cÃ³ thá»ƒ táº¡o Airflow DAG:

```python
from airflow import DAG
from airflow.operators.bash_operator import BashOperator
from datetime import datetime, timedelta

default_args = {
    'owner': 'weather-team',
    'depends_on_past': False,
    'start_date': datetime(2024, 1, 1),
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 1,
    'retry_delay': timedelta(minutes=5),
}

dag = DAG(
    'weather_lstm_forecast',
    default_args=default_args,
    description='Dá»± Ä‘oÃ¡n thá»i tiáº¿t 7 ngÃ y vá»›i LSTM',
    schedule_interval=timedelta(days=1),  # Cháº¡y má»—i ngÃ y
    catchup=False,
)

forecast_task = BashOperator(
    task_id='run_lstm_forecast',
    bash_command='cd /path/to/spark-ml && python spark_lstm_forecast.py',
    dag=dag,
)

forecast_task
```

## ğŸ“š TÃ i Liá»‡u Tham Kháº£o

- [PySpark Documentation](https://spark.apache.org/docs/latest/api/python/)
- [TensorFlow/Keras LSTM Guide](https://www.tensorflow.org/guide/keras/rnn)
- [PostgreSQL JDBC Driver](https://jdbc.postgresql.org/)
- [MinIO Python SDK](https://min.io/docs/minio/linux/developers/python/API.html)

## ğŸ“ Ghi ChÃº

- MÃ´ hÃ¬nh LSTM Ä‘Æ°á»£c huáº¥n luyá»‡n láº¡i má»—i láº§n cháº¡y (cÃ³ thá»ƒ tá»‘i Æ°u báº±ng cÃ¡ch lÆ°u model)
- Dá»± Ä‘oÃ¡n Ä‘Æ°á»£c thá»±c hiá»‡n theo tá»«ng giá» (hourly)
- CÃ³ thá»ƒ má»Ÿ rá»™ng Ä‘á»ƒ dá»± Ä‘oÃ¡n nhiá»u thÃ nh phá»‘ song song
- CÃ³ thá»ƒ tÃ­ch há»£p vá»›i Grafana Ä‘á»ƒ visualize real-time

## âœ… Checklist TrÆ°á»›c Khi Cháº¡y

- [ ] MinIO server Ä‘ang cháº¡y vÃ  cÃ³ dá»¯ liá»‡u
- [ ] PostgreSQL server Ä‘ang cháº¡y
- [ ] Database vÃ  table Ä‘Ã£ Ä‘Æ°á»£c táº¡o
- [ ] Táº¥t cáº£ dependencies Ä‘Ã£ Ä‘Æ°á»£c cÃ i Ä‘áº·t
- [ ] Config files Ä‘Ã£ Ä‘Æ°á»£c cáº­p nháº­t Ä‘Ãºng
- [ ] CÃ³ Ä‘á»§ RAM (Ã­t nháº¥t 4GB cho Spark driver)

---

**TÃ¡c giáº£**: Weather Analysis Team  
**NgÃ y cáº­p nháº­t**: 2024-01-15

