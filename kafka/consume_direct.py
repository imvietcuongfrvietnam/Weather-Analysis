import json
import time
import os
import threading
import subprocess
from datetime import datetime
from kafka import KafkaConsumer

# --- C·∫§U H√åNH ---
BOOTSTRAP_SERVERS = ['localhost:9092']

# üëá [QUAN TR·ªåNG] Thay t√™n n√†y b·∫±ng t√™n pod th·∫≠t c·ªßa b·∫°n (l·∫•y t·ª´ 'kubectl get pods')
NAMENODE_POD = "namenode-749c6d6bf7-jgg9z"  # V√≠ d·ª• l·∫•y t·ª´ ·∫£nh b·∫°n g·ª≠i

# =============================================================================
# 1. BASE CLASS (Gi·ªØ nguy√™n)
# =============================================================================
class BaseConsumer(threading.Thread):
    def __init__(self, topic, group_id):
        threading.Thread.__init__(self)
        self.topic = topic
        self.group_id = group_id
        self.stop_event = threading.Event()
        self.consumer = None

    def _connect_kafka(self):
        try:
            self.consumer = KafkaConsumer(
                self.topic,
                bootstrap_servers=BOOTSTRAP_SERVERS,
                group_id=self.group_id,
                auto_offset_reset='latest',
                enable_auto_commit=True,
                value_deserializer=lambda x: json.loads(x.decode('utf-8'))
            )
            print(f"‚úÖ [{self.__class__.__name__}] ƒê√£ n·ªëi Kafka topic '{self.topic}'")
        except Exception as e:
            print(f"‚ùå [{self.__class__.__name__}] L·ªói k·∫øt n·ªëi Kafka: {e}")

    def process_message(self, data):
        raise NotImplementedError

    def run(self):
        self._connect_kafka()
        if not self.consumer: return
        print(f"üöÄ [{self.__class__.__name__}] B·∫Øt ƒë·∫ßu ch·∫°y...")
        while not self.stop_event.is_set():
            msg_pack = self.consumer.poll(timeout_ms=1000)
            for tp, messages in msg_pack.items():
                for msg in messages:
                    self.process_message(msg.value)
        self.consumer.close()
        print(f"üõë [{self.__class__.__name__}] ƒê√£ d·ª´ng.")

    def stop(self):
        self.stop_event.set()

# =============================================================================
# 2. HDFS CONSUMER (PHI√äN B·∫¢N S·ª¨ D·ª§NG KUBECTL - FIX L·ªñI DATANODE)
# =============================================================================
class HDFSConsumerBase(BaseConsumer):
    def __init__(self, topic, hdfs_folder, batch_size=50):
        super().__init__(topic, group_id='hdfs-archiver-group')
        self.hdfs_folder = hdfs_folder
        self.batch_size = batch_size
        self.buffer = [] 
        
        # T·∫°o th∆∞ m·ª•c tr√™n HDFS ngay khi kh·ªüi ƒë·ªông
        self._ensure_hdfs_dir()

    def _ensure_hdfs_dir(self):
        """D√πng kubectl ƒë·ªÉ ra l·ªánh cho Namenode t·∫°o th∆∞ m·ª•c"""
        try:
            cmd = f"kubectl exec {NAMENODE_POD} -- hdfs dfs -mkdir -p {self.hdfs_folder}"
            subprocess.run(cmd, shell=True, check=False, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
            print(f"üìÇ ƒê√£ ƒë·∫£m b·∫£o th∆∞ m·ª•c HDFS: {self.hdfs_folder}")
        except Exception as e:
            print(f"‚ö†Ô∏è C·∫£nh b√°o t·∫°o th∆∞ m·ª•c: {e}")

    def flush_buffer(self):
        if not self.buffer: return

        # 1. T·∫°o file t·∫°m tr√™n m√°y t√≠nh c·ªßa b·∫°n (Localhost)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"data_{timestamp}.json"
        local_path = f"/tmp/{filename}" # L∆∞u v√†o th∆∞ m·ª•c t·∫°m c·ªßa Linux
        
        try:
            # Ghi d·ªØ li·ªáu v√†o file t·∫°m ·ªü m√°y th·∫≠t
            with open(local_path, 'w', encoding='utf-8') as f:
                for record in self.buffer:
                    f.write(json.dumps(record) + "\n")
            
            # 2. Copy file t·ª´ m√°y th·∫≠t v√†o b√™n trong Pod Namenode
            pod_tmp_path = f"/tmp/{filename}"
            # L·ªánh: kubectl cp /tmp/local.json namenode:/tmp/remote.json
            cp_cmd = f"kubectl cp {local_path} {NAMENODE_POD}:{pod_tmp_path}"
            subprocess.check_call(cp_cmd, shell=True, stdout=subprocess.DEVNULL)

            # 3. Ra l·ªánh cho Namenode ƒë∆∞a file v√†o HDFS ch√≠nh th·ª©c
            # L·ªánh: hdfs dfs -moveFromLocal ...
            hdfs_cmd = f"kubectl exec {NAMENODE_POD} -- hdfs dfs -moveFromLocal {pod_tmp_path} {self.hdfs_folder}/{filename}"
            subprocess.check_call(hdfs_cmd, shell=True, stdout=subprocess.DEVNULL)

            print(f"üíæ [{self.__class__.__name__}] ƒê√£ ghi {len(self.buffer)} d√≤ng v√†o HDFS: {self.hdfs_folder}/{filename}")
            
            # D·ªçn d·∫πp file r√°c
            os.remove(local_path)
            self.buffer = [] 

        except Exception as e:
            print(f"‚ùå L·ªói ghi HDFS qua Kubectl: {e}")

    def process_message(self, data):
        self.buffer.append(data)
        if len(self.buffer) >= self.batch_size:
            self.flush_buffer()

# =============================================================================
# 3. STREAMING & IMPLEMENTATION (Gi·ªØ nguy√™n logic c≈©)
# =============================================================================
class SparkStreamingSimBase(BaseConsumer):
    def __init__(self, topic):
        super().__init__(topic, group_id='spark-streaming-group')
    def process_message(self, data):
        self.process_logic(data)
    def process_logic(self, data): pass

class WeatherHDFSConsume(HDFSConsumerBase):
    def __init__(self):
        super().__init__(topic='nyc-weather-raw', hdfs_folder='/nyc_data/weather')

class WeatherStreamingConsume(SparkStreamingSimBase):
    def __init__(self):
        super().__init__(topic='nyc-weather-raw')
    def process_logic(self, data):
        if data.get('temperature', 0) > 30:
            print(f"üî• [ALERT-WEATHER] N√≥ng qu√° ({data.get('temperature')}¬∞C)")

# =============================================================================
# MAIN
# =============================================================================
if __name__ == "__main__":
    print(f"--- CONSUMER SYSTEM (Using Pod: {NAMENODE_POD}) ---")
    
    # Danh s√°ch worker
    workers = [
        WeatherHDFSConsume(),
        WeatherStreamingConsume()
    ]

    try:
        for w in workers: w.start()
        while True: time.sleep(1)
    except KeyboardInterrupt:
        print("\nƒêang d·ª´ng...")
        for w in workers: w.stop()
        for w in workers: w.join()