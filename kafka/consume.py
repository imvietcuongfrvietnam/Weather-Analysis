import json
import time
import os
import threading
from datetime import datetime
from kafka import KafkaConsumer
from hdfs import InsecureClient

# --- C·∫§U H√åNH CHUNG ---
BOOTSTRAP_SERVERS = ['localhost:9092']
HDFS_URL = 'http://localhost:30070' # Nh·ªõ port-forward tr∆∞·ªõc khi ch·∫°y
HDFS_USER = 'root'

# =============================================================================
# T·∫¶NG 1: BASE CONSUMER (L·ªöP CHA CAO NH·∫§T)
# Nhi·ªám v·ª•: K·∫øt n·ªëi Kafka, qu·∫£n l√Ω v√≤ng l·∫∑p, x·ª≠ l√Ω l·ªói m·∫°ng.
# =============================================================================
class BaseConsumer(threading.Thread):
    def __init__(self, topic, group_id, batch_size=1):
        threading.Thread.__init__(self)
        self.topic = topic
        self.group_id = group_id
        self.batch_size = batch_size
        self.buffer = []
        self.stop_event = threading.Event()
        self.consumer = None

    def _connect(self):
        try:
            self.consumer = KafkaConsumer(
                self.topic,
                bootstrap_servers=BOOTSTRAP_SERVERS,
                group_id=self.group_id,
                auto_offset_reset='latest',
                enable_auto_commit=True,
                value_deserializer=lambda x: json.loads(x.decode('utf-8'))
            )
            print(f"‚úÖ [{self.__class__.__name__}] ƒê√£ n·ªëi Kafka topic '{self.topic}' (Group: {self.group_id})")
        except Exception as e:
            print(f"‚ùå [{self.__class__.__name__}] L·ªói k·∫øt n·ªëi Kafka: {e}")

    def process_record(self, record):
        """H√†m n√†y x·ª≠ l√Ω t·ª´ng b·∫£n ghi l·∫ª (D√†nh cho Streaming)"""
        pass

    def process_batch(self, batch):
        """H√†m n√†y x·ª≠ l√Ω c·∫£ l√¥ b·∫£n ghi (D√†nh cho HDFS)"""
        pass

    def run(self):
        self._connect()
        if not self.consumer: return

        print(f"üöÄ [{self.__class__.__name__}] B·∫Øt ƒë·∫ßu ch·∫°y...")
        
        while not self.stop_event.is_set():
            msg_pack = self.consumer.poll(timeout_ms=1000)
            
            for tp, messages in msg_pack.items():
                for msg in messages:
                    data = msg.value
                    
                    # C√°ch 1: X·ª≠ l√Ω t·ª´ng d√≤ng (cho Streaming)
                    if self.batch_size == 1:
                        self.process_record(data)
                    
                    # C√°ch 2: Gom batch (cho HDFS)
                    else:
                        self.buffer.append(data)
                        if len(self.buffer) >= self.batch_size:
                            self.process_batch(self.buffer)
                            self.buffer = [] # Reset r·ªï
        
        self.consumer.close()
        print(f"üõë [{self.__class__.__name__}] ƒê√£ d·ª´ng.")

    def stop(self):
        self.stop_event.set()


# =============================================================================
# T·∫¶NG 2: NH√ìM CONSUMER THEO CH·ª®C NƒÇNG
# =============================================================================

# --- NH√ìM 1: HDFS ARCHIVER (Batch Layer) ---
class HDFSConsumerBase(BaseConsumer):
    def __init__(self, topic, hdfs_folder):
        # HDFS c·∫ßn gom batch l·ªõn (v√≠ d·ª• 50 tin) m·ªõi ghi ƒë·ªÉ t·ªëi ∆∞u
        super().__init__(topic, group_id='hdfs-archiver-group', batch_size=50)
        self.hdfs_folder = hdfs_folder
        self.client = self._connect_hdfs()

    def _connect_hdfs(self):
        try:
            client = InsecureClient(HDFS_URL, user=HDFS_USER)
            client.makedirs(self.hdfs_folder) # T·∫°o folder n·∫øu ch∆∞a c√≥
            return client
        except Exception as e:
            print(f"‚ö†Ô∏è Kh√¥ng n·ªëi ƒë∆∞·ª£c HDFS: {e}")
            return None

    def process_batch(self, batch):
        if not self.client: return
        
        # T·∫°o t√™n file: topic_timestamp.json
        filename = f"{self.topic}_{int(time.time())}.json"
        full_path = os.path.join(self.hdfs_folder, filename)
        
        try:
            # Ghi file JSON Lines
            content = "\n".join([json.dumps(r) for r in batch])
            with self.client.write(full_path, encoding='utf-8') as writer:
                writer.write(content)
            print(f"üíæ [{self.__class__.__name__}] ƒê√£ ghi {len(batch)} d√≤ng v√†o {full_path}")
        except Exception as e:
            print(f"‚ùå L·ªói ghi HDFS: {e}")

# --- NH√ìM 2: SPEED LAYER (Gi·∫£ l·∫≠p Spark Streaming b·∫±ng Python) ---
# L∆∞u √Ω: Trong th·ª±c t·∫ø Production, l·ªõp n√†y s·∫Ω l√† code Spark Scala/PySpark ri√™ng bi·ªát.
# Nh∆∞ng ·ªü ƒë√¢y ta vi·∫øt class Python ƒë·ªÉ demo logic x·ª≠ l√Ω lu·ªìng theo y√™u c·∫ßu OOP c·ªßa b·∫°n.
class SpeedLayerConsumerBase(BaseConsumer):
    def __init__(self, topic):
        # Speed Layer c·∫ßn x·ª≠ l√Ω ngay l·∫≠p t·ª©c (Batch size = 1)
        super().__init__(topic, group_id='spark-streaming-group', batch_size=1)

    def process_record(self, data):
        raise NotImplementedError("Class con ph·∫£i t·ª± ƒë·ªãnh nghƒ©a logic c·∫£nh b√°o!")


# =============================================================================
# T·∫¶NG 3: C√ÅC CONSUMER C·ª§ TH·ªÇ (IMPLEMENTATION)
# =============================================================================

# --- C·ª§M HDFS CONSUMERS ---
class WeatherHDFSConsumer(HDFSConsumerBase):
    def __init__(self):
        super().__init__(topic='nyc-weather-raw', hdfs_folder='/nyc_data/weather')

class NYC311HDFSConsumer(HDFSConsumerBase):
    def __init__(self):
        super().__init__(topic='nyc-311-data', hdfs_folder='/nyc_data/311')

class TaxiHDFSConsumer(HDFSConsumerBase):
    def __init__(self):
        super().__init__(topic='nyc-taxi-data', hdfs_folder='/nyc_data/taxi')

class CollisionHDFSConsumer(HDFSConsumerBase):
    def __init__(self):
        super().__init__(topic='nyc-collision-data', hdfs_folder='/nyc_data/collision')


# --- C·ª§M SPEED LAYER CONSUMERS ---
class WeatherAlertConsumer(SpeedLayerConsumerBase):
    def __init__(self):
        super().__init__(topic='nyc-weather-raw')
    
    def process_record(self, data):
        # Logic nghi·ªáp v·ª•: C·∫£nh b√°o nhi·ªát ƒë·ªô
        temp = data.get('temperature', 0)
        if temp > 30:
            print(f"üî• [ALERT-WEATHER] N√≥ng qu√° ({temp}¬∞C) t·∫°i {data.get('location')}")

class TaxiRealtimeConsumer(SpeedLayerConsumerBase):
    def __init__(self):
        super().__init__(topic='nyc-taxi-data')

    def process_record(self, data):
        # Logic nghi·ªáp v·ª•: Theo d√µi doanh thu taxi
        amount = data.get('total_amount', 0)
        if amount > 80:
            print(f"üöï [ALERT-TAXI] Chuy·∫øn ƒëi VIP gi√° cao: ${amount}")

# ... B·∫°n c√≥ th·ªÉ vi·∫øt th√™m CollisionAlertConsumer, v.v...


# =============================================================================
# MAIN: CH·∫†Y TO√ÄN B·ªò H·ªÜ TH·ªêNG
# =============================================================================
if __name__ == "__main__":
    print("--- KH·ªûI ƒê·ªòNG H·ªÜ TH·ªêNG CONSUMER OOP ---")
    
    # 1. Kh·ªüi t·∫°o danh s√°ch c√°c Consumer mu·ªën ch·∫°y
    consumers = [
        # Nh√≥m HDFS (L∆∞u tr·ªØ)
        WeatherHDFSConsumer(),
        # NYC311HDFSConsumer(), # B·ªè comment n·∫øu mu·ªën ch·∫°y
        # TaxiHDFSConsumer(),
        
        # Nh√≥m Speed Layer (C·∫£nh b√°o)
        WeatherAlertConsumer(),
        # TaxiRealtimeConsumer()
    ]

    # 2. B·∫Øt ƒë·∫ßu ch·∫°y t·∫•t c·∫£ c√°c lu·ªìng
    try:
        for c in consumers:
            c.start()
        
        # Gi·ªØ ch∆∞∆°ng tr√¨nh ch·∫°y
        while True:
            time.sleep(1)
            
    except KeyboardInterrupt:
        print("\nƒêang d·ª´ng h·ªá th·ªëng...")
        for c in consumers:
            c.stop()
        for c in consumers:
            c.join()
        print("‚úÖ ƒê√£ t·∫Øt.")